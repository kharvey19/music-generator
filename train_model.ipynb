{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pcpHiSTbYSbg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRZT9SdIYoDN"
      },
      "source": [
        "Toy Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XTSbVBGYYXxc"
      },
      "outputs": [],
      "source": [
        "chord_to_idx = {'C_major': 0, 'F_major': 1, 'G_major': 2}\n",
        "note_to_idx = {'E4': 64, 'G4': 67, 'A4': 69, 'C5':72, 'F4':65, 'D4':62}\n",
        "\n",
        "# simple music peice, each pair is a (chord, melody note) that occures at one time step\n",
        "data = [\n",
        "    ('C_major', 'E4'),\n",
        "    ('C_major', 'G4'),\n",
        "    ('F_major', 'A4'),\n",
        "    ('G_major', 'G4'),\n",
        "    ('C_major', 'E4'),\n",
        "    ('C_major', 'C5'),\n",
        "    ('F_major', 'F4'),\n",
        "    ('G_major', 'D4'),\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cDfYF_eNZPPM"
      },
      "outputs": [],
      "source": [
        "input_seq = []\n",
        "for chord, _ in data:\n",
        "  input_seq.append(chord_to_idx[chord])\n",
        "\n",
        "# PyTorch's sequence models expect inut with two dimensions\n",
        "# This makes it one batch with 8 time steps\n",
        "input_seq = torch.tensor(input_seq).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLZLDctJaEoO",
        "outputId": "bb2281cf-ac58-44f1-e2d8-a2d94ffdefe0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 0, 1, 2, 0, 0, 1, 2]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5n89BUQQagB9"
      },
      "outputs": [],
      "source": [
        "target_seq = []\n",
        "for _, note in data:\n",
        "  target_seq.append(note_to_idx[note])\n",
        "target_seq = torch.tensor(target_seq).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj24AqsPbSgL",
        "outputId": "d80d3306-71ed-49a7-b4e6-64b68a614357"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[64, 67, 69, 67, 64, 72, 65, 62]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ6HPSd8bXSf"
      },
      "source": [
        "LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KNlk3WyzbTUF"
      },
      "outputs": [],
      "source": [
        "class MelodyLSTM(nn.Module):\n",
        "  # input_dim: number of possible chord types, hidden_dim: size of the internal representation, output_dim: number of possible note outputs\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(input_dim, hidden_dim) # maps each chord index to a vector\n",
        "    self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim) # maps the LSTM's output to a note prediction\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    x, _ = self.lstm(x)\n",
        "    return self.fc(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jEgHmt3cK-K"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WtewGgr_cAn5"
      },
      "outputs": [],
      "source": [
        "input_dim = len(chord_to_idx)\n",
        "hidden_dim = 64\n",
        "output_dim = 128\n",
        "\n",
        "model = MelodyLSTM(input_dim, hidden_dim, output_dim)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAWaD3FRdD45",
        "outputId": "44d73c1a-a7ed-4367-f92b-928c12c63178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 100, Loss: 0.0055\n",
            "Epoch 200, Loss: 0.0022\n",
            "Epoch 300, Loss: 0.0012\n",
            "Epoch 400, Loss: 0.0008\n",
            "Epoch 500, Loss: 0.0006\n",
            "Epoch 600, Loss: 0.0004\n",
            "Epoch 700, Loss: 0.0003\n",
            "Epoch 800, Loss: 0.0003\n",
            "Epoch 900, Loss: 0.0002\n",
            "Epoch 1000, Loss: 0.0002\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1000):\n",
        "  optimizer.zero_grad()\n",
        "  output = model(input_seq)\n",
        "  loss = loss_fn(output.view(-1, output_dim), target_seq.view(-1))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if (epoch + 1) % 100 == 0:\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp_8-xbadmMD"
      },
      "source": [
        "Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "U0nU519udhYc",
        "outputId": "3184e4b3-463d-4ec7-b224-ab958c6ab165"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_aeb0bcc1-f673-4cfe-be8f-29d513606d93\", \"melody_lstm.pth\", 170096)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"melody_lstm.pth\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"melody_lstm.pth\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
